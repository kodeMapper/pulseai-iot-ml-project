"""
PulseAI - Hyperparameter Optimization (Task 1.5)
Bayesian optimization with Optuna for top-performing models
"""

import pandas as pd
import numpy as np
import joblib
import json
from datetime import datetime
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
import optuna
from optuna.samplers import TPESampler
import warnings
warnings.filterwarnings('ignore')
optuna.logging.set_verbosity(optuna.logging.WARNING)

print("="*70)
print("PulseAI Hyperparameter Optimization (Task 1.5)")
print("Bayesian Optimization with Optuna")
print("="*70)

# Load dataset
print("\nüìÇ Loading engineered dataset...")
df = pd.read_csv('dataset_engineered.csv')

feature_cols = [col for col in df.columns 
               if col not in ['Patient ID', 'Target', 'Augmentation_Method', 'Sl.No']]
X = df[feature_cols].values
y = df['Target'].values

print(f"   Total samples: {len(df)}")
print(f"   Total features: {len(feature_cols)}")

# Use 70/30 split
print("\nüîÄ Creating train-test split (70/30)...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.30, random_state=42, stratify=y
)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Optimization 1: Extra Trees (current best at 52.76%)
print("\n" + "="*70)
print("Optimizing Extra Trees (Current Best: 52.76%)")
print("="*70)

def objective_extra_trees(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 200, 800),
        'max_depth': trial.suggest_int('max_depth', 10, 40),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),
        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),
        'random_state': 42
    }
    
    model = ExtraTreesClassifier(**params)
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy', n_jobs=-1)
    return cv_scores.mean()

print("\nüîç Running Optuna optimization (50 trials)...")
study_et = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))
study_et.optimize(objective_extra_trees, n_trials=50, show_progress_bar=True)

print(f"\n‚úÖ Best CV Score: {study_et.best_value*100:.2f}%")
print(f"   Best parameters:")
for key, value in study_et.best_params.items():
    print(f"      {key}: {value}")

# Train final model with best params
best_et_model = ExtraTreesClassifier(**study_et.best_params, random_state=42)
best_et_model.fit(X_train_scaled, y_train)
et_pred = best_et_model.predict(X_test_scaled)
et_test_acc = accuracy_score(y_test, et_pred)

print(f"\nüéØ Test Accuracy: {et_test_acc*100:.2f}%")

# Optimization 2: LightGBM
print("\n" + "="*70)
print("Optimizing LightGBM (Previous: 51.26%)")
print("="*70)

def objective_lightgbm(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 200, 1000),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'max_depth': trial.suggest_int('max_depth', 3, 15),
        'num_leaves': trial.suggest_int('num_leaves', 20, 100),
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
        'random_state': 42,
        'verbose': -1
    }
    
    model = LGBMClassifier(**params)
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy', n_jobs=-1)
    return cv_scores.mean()

print("\nüîç Running Optuna optimization (50 trials)...")
study_lgbm = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))
study_lgbm.optimize(objective_lightgbm, n_trials=50, show_progress_bar=True)

print(f"\n‚úÖ Best CV Score: {study_lgbm.best_value*100:.2f}%")
print(f"   Best parameters:")
for key, value in study_lgbm.best_params.items():
    print(f"      {key}: {value}")

# Train final model
best_lgbm_model = LGBMClassifier(**study_lgbm.best_params, random_state=42, verbose=-1)
best_lgbm_model.fit(X_train_scaled, y_train)
lgbm_pred = best_lgbm_model.predict(X_test_scaled)
lgbm_test_acc = accuracy_score(y_test, lgbm_pred)

print(f"\nüéØ Test Accuracy: {lgbm_test_acc*100:.2f}%")

# Optimization 3: Random Forest
print("\n" + "="*70)
print("Optimizing Random Forest (Previous: 51.26%)")
print("="*70)

def objective_random_forest(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 200, 800),
        'max_depth': trial.suggest_int('max_depth', 10, 40),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),
        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),
        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),
        'random_state': 42
    }
    
    model = RandomForestClassifier(**params)
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy', n_jobs=-1)
    return cv_scores.mean()

print("\nüîç Running Optuna optimization (50 trials)...")
study_rf = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))
study_rf.optimize(objective_random_forest, n_trials=50, show_progress_bar=True)

print(f"\n‚úÖ Best CV Score: {study_rf.best_value*100:.2f}%")
print(f"   Best parameters:")
for key, value in study_rf.best_params.items():
    print(f"      {key}: {value}")

# Train final model
best_rf_model = RandomForestClassifier(**study_rf.best_params, random_state=42)
best_rf_model.fit(X_train_scaled, y_train)
rf_pred = best_rf_model.predict(X_test_scaled)
rf_test_acc = accuracy_score(y_test, rf_pred)

print(f"\nüéØ Test Accuracy: {rf_test_acc*100:.2f}%")

# Optimization 4: CatBoost
print("\n" + "="*70)
print("Optimizing CatBoost (Previous: 50.75%)")
print("="*70)

def objective_catboost(trial):
    params = {
        'iterations': trial.suggest_int('iterations', 200, 1000),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'depth': trial.suggest_int('depth', 3, 10),
        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),
        'border_count': trial.suggest_int('border_count', 32, 255),
        'random_seed': 42,
        'verbose': False
    }
    
    model = CatBoostClassifier(**params)
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy', n_jobs=-1)
    return cv_scores.mean()

print("\nüîç Running Optuna optimization (50 trials)...")
study_cb = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))
study_cb.optimize(objective_catboost, n_trials=50, show_progress_bar=True)

print(f"\n‚úÖ Best CV Score: {study_cb.best_value*100:.2f}%")
print(f"   Best parameters:")
for key, value in study_cb.best_params.items():
    print(f"      {key}: {value}")

# Train final model
best_cb_model = CatBoostClassifier(**study_cb.best_params, random_seed=42, verbose=False)
best_cb_model.fit(X_train_scaled, y_train)
cb_pred = best_cb_model.predict(X_test_scaled)
cb_test_acc = accuracy_score(y_test, cb_pred)

print(f"\nüéØ Test Accuracy: {cb_test_acc*100:.2f}%")

# Compare optimized models
print("\n" + "="*70)
print("üìä Optimized Models Comparison")
print("="*70)

optimized_results = {
    'Extra_Trees_Optimized': et_test_acc,
    'LightGBM_Optimized': lgbm_test_acc,
    'Random_Forest_Optimized': rf_test_acc,
    'CatBoost_Optimized': cb_test_acc
}

print(f"\n{'Model':<30} {'Test Acc':<12} {'Improvement'}")
print("-"*60)
baseline_scores = {
    'Extra_Trees_Optimized': 0.5276,
    'LightGBM_Optimized': 0.5126,
    'Random_Forest_Optimized': 0.5126,
    'CatBoost_Optimized': 0.5075
}

for name, acc in sorted(optimized_results.items(), key=lambda x: x[1], reverse=True):
    baseline = baseline_scores[name]
    improvement = (acc - baseline) * 100
    print(f"{name:<30} {acc*100:>10.2f}%  {improvement:+.2f}%")

# Find best model
best_model_name = max(optimized_results.items(), key=lambda x: x[1])[0]
best_acc = optimized_results[best_model_name]

print(f"\nüèÜ Best Optimized Model: {best_model_name}")
print(f"   Test Accuracy: {best_acc*100:.2f}%")

# Save best model
model_map = {
    'Extra_Trees_Optimized': best_et_model,
    'LightGBM_Optimized': best_lgbm_model,
    'Random_Forest_Optimized': best_rf_model,
    'CatBoost_Optimized': best_cb_model
}

best_model = model_map[best_model_name]
best_pred = best_model.predict(X_test_scaled)

joblib.dump(best_model, 'models/optimized_best_model.pkl')
joblib.dump(scaler, 'models/optimized_scaler.pkl')
print(f"   üíæ Best model saved")

# Detailed evaluation
print(f"\nüìã Detailed Classification Report (Best Optimized Model):")
print("="*70)
print(classification_report(y_test, best_pred, 
                          target_names=['Low Risk', 'Medium Risk', 'High Risk'],
                          digits=3))

# Confusion matrix
print(f"\nüî¢ Confusion Matrix:")
cm = confusion_matrix(y_test, best_pred)
print(f"\n                 Predicted")
print(f"              Low  Med  High")
print(f"Actual Low    {cm[0,0]:>3}  {cm[0,1]:>3}  {cm[0,2]:>3}")
print(f"       Med    {cm[1,0]:>3}  {cm[1,1]:>3}  {cm[1,2]:>3}")
print(f"       High   {cm[2,0]:>3}  {cm[2,1]:>3}  {cm[2,2]:>3}")

# Per-class performance
print(f"\nüìä Per-Class Performance:")
for i, class_name in enumerate(['Low Risk', 'Medium Risk', 'High Risk']):
    class_acc = cm[i,i] / cm[i].sum() if cm[i].sum() > 0 else 0
    print(f"   {class_name}: {class_acc*100:.2f}%")

# Save metadata
metadata = {
    'timestamp': datetime.now().isoformat(),
    'task': 'Task 1.5 - Hyperparameter Optimization',
    'optimization_trials': 50,
    'dataset': {
        'total_samples': len(df),
        'train_samples': len(X_train),
        'test_samples': len(X_test),
        'features': len(feature_cols)
    },
    'optimized_models': {
        name: {
            'test_accuracy': float(acc),
            'baseline_accuracy': float(baseline_scores[name]),
            'improvement': float((acc - baseline_scores[name]) * 100)
        }
        for name, acc in optimized_results.items()
    },
    'best_model': best_model_name,
    'best_test_accuracy': float(best_acc),
    'best_parameters': study_et.best_params if best_model_name == 'Extra_Trees_Optimized' else
                      study_lgbm.best_params if best_model_name == 'LightGBM_Optimized' else
                      study_rf.best_params if best_model_name == 'Random_Forest_Optimized' else
                      study_cb.best_params,
    'confusion_matrix': cm.tolist()
}

with open('models/optimized_metadata.json', 'w') as f:
    json.dump(metadata, f, indent=4)

print(f"\nüíæ Metadata saved")

# Final Phase 1 summary
print(f"\n" + "="*70)
print(f"üéâ PHASE 1 COMPLETE - Final Summary")
print(f"="*70)

print(f"\n   Progress Timeline:")
print(f"   1. Baseline: 43.00%")
print(f"   2. Data Augmentation: 150 ‚Üí 663 samples")
print(f"   3. Feature Engineering: 3 ‚Üí 64 features")
print(f"   4. Traditional ML: 52.26% (+9.26%)")
print(f"   5. Deep Learning: 50.25% (-2.01%)")
print(f"   6. Advanced Ensemble: 52.76% (+0.50%)")
print(f"   7. Hyperparameter Optimization: {best_acc*100:.2f}% ({(best_acc-0.5276)*100:+.2f}%)")

total_improvement = (best_acc - 0.43) * 100
print(f"\n   üìä Total Improvement: +{total_improvement:.2f}%")

target = 0.85
gap = (target - best_acc) * 100
achievement = (best_acc / target) * 100

print(f"\n   üéØ Target: 85%")
print(f"   ‚úÖ Achieved: {best_acc*100:.2f}% ({achievement:.1f}% of target)")
print(f"   üîç Gap remaining: {gap:.2f}%")

print(f"\n   üìà Key Findings:")
print(f"   - Data augmentation was highly effective (+10%)")
print(f"   - Feature engineering provided minimal benefit")
print(f"   - Deep learning underperformed (small dataset)")
print(f"   - Tree-based ensembles performed best")
print(f"   - Medium Risk class easiest to predict (~80%)")
print(f"   - Low and High Risk challenging (~40%)")

if best_acc >= 0.60:
    print(f"\n   ‚úÖ GOOD PROGRESS - Exceeded 60% milestone")
elif best_acc >= 0.55:
    print(f"\n   üéØ MODERATE PROGRESS - Reached 55%+ milestone")
else:
    print(f"\n   ‚ö†Ô∏è  LIMITED PROGRESS - Below 55%")

print(f"\n   üí° Recommendations for further improvement:")
print(f"   1. Collect more real-world data (current: 150 ‚Üí 663 augmented)")
print(f"   2. Explore domain-specific features (medical knowledge)")
print(f"   3. Investigate class imbalance handling (especially Low/High)")
print(f"   4. Consider ensemble of ensembles")
print(f"   5. Review data quality and feature relevance")

print(f"\n" + "="*70)
print(f"üéâ Task 1.5 Complete - All Phase 1 Tasks Finished!")
print(f"="*70)
