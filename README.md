# PulseAI â€“ IoT Health Monitoring (ML)

**Status**: Phase 1 Complete âœ… | **Best Accuracy**: 52.76% | **Target**: 85%

Classify patient health risk as **Low**, **Medium**, or **High** using IoT-derived vitals (Temperature, ECG, Pressure). This project implements a comprehensive machine learning pipeline with data augmentation, feature engineering, traditional ML, deep learning, and advanced ensemble techniques.

## ğŸ¯ Project Status

**Phase 1 Complete** - All planned tasks (1.1-1.5) finished with the following results:

- âœ… **Data Augmentation**: 150 â†’ 663 samples (+10% accuracy improvement)
- âœ… **Feature Engineering**: 3 â†’ 64 features (0% improvement - curse of dimensionality)
- âœ… **Traditional ML**: Logistic Regression 52.26%
- âœ… **Deep Learning**: MLP, 1D-CNN, Deep MLP (underperformed at 50.25%)
- âœ… **Advanced Ensemble**: Extra Trees 52.76% â­ **BEST MODEL**
- âœ… **Hyperparameter Optimization**: Optuna (51.76% - slight overfit)

**Total Improvement**: +9.76% over baseline (43% â†’ 52.76%)  
**Gap to Target**: 32.24 percentage points remaining

ğŸ“„ **Full Report**: See [`PHASE1_FINAL_REPORT.md`](reports/PHASE1_FINAL_REPORT.md)

## ğŸ“ Repository Contents

### Core Files
- `dataset.csv` â€” Original dataset (150 samples, 3 features)
- `dataset_augmented.csv` â€” Augmented dataset (663 samples)
- `dataset_engineered.csv` â€” Augmented + 64 engineered features
- `PROGRESS_SUMMARY_FINAL.md` â€” Quick progress overview
- `PROJECT_ROADMAP.md` â€” Original improvement plan

### Models & Training
```
models/
â”œâ”€â”€ ensemble_best_model.pkl          # Extra Trees (52.76%) â­
â”œâ”€â”€ ensemble_scaler.pkl              # StandardScaler
â”œâ”€â”€ corrected_best_model.pkl         # Logistic Regression (52.26%)
â”œâ”€â”€ mlp_model.keras                  # Deep learning models
â”œâ”€â”€ *_metadata.json                  # Training results & metrics
```

### Source Code
```
src/
â”œâ”€â”€ corrected_training.py            # Traditional ML training
â”œâ”€â”€ advanced_ensemble.py             # CatBoost, LightGBM, XGBoost, Stacking
â”œâ”€â”€ deep_learning_models.py          # MLP, 1D-CNN, Deep MLP
â”œâ”€â”€ hyperparameter_optimization.py   # Optuna Bayesian optimization
â”œâ”€â”€ data_augmentation.py             # SMOTE + Gaussian noise
â”œâ”€â”€ advanced_features.py             # Feature engineering pipeline
â””â”€â”€ predictor.py                     # Inference module
```

### Reports & Analysis
```
reports/
â”œâ”€â”€ PHASE1_FINAL_REPORT.md           # Comprehensive Phase 1 report
â”œâ”€â”€ EXECUTIVE_SUMMARY.md             # High-level overview
â”œâ”€â”€ classification_reports.txt       # Per-model detailed results
â”œâ”€â”€ *.png                            # Visualizations
```

## Dataset

Each row represents a single observation for a patient.

Columns:
- `Sl.No` (int): serial number/index (not used for modeling)
- `Patient ID` (int): anonymized patient identifier
- `Temperature Data` (numeric): temperature reading (unit depends on source, assumed Â°C)
- `ECG Data` (numeric): ECG-derived feature
- `Pressure Data` (numeric): blood pressure related value (assumed mmHg)
- `Target` (int): encoded label of patient condition

Label encoding (assumed):
- `0` â†’ Low
- `1` â†’ Medium
- `2` â†’ High

Note: If your labeling differs, adjust the mapping in the notebook where predictions are interpreted.

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+ and pip
- Virtual environment recommended

### Installation

```powershell
# Create and activate virtual environment
py -3 -m venv .venv
.\.venv\Scripts\Activate.ps1

# Install dependencies
python -m pip install --upgrade pip
pip install -r requirements.txt
```

### Using the Best Model (Extra Trees - 52.76%)

```python
import joblib
import numpy as np

# Load best model and scaler
model = joblib.load('models/ensemble_best_model.pkl')
scaler = joblib.load('models/ensemble_scaler.pkl')

# Prepare input (Temperature, ECG, Pressure + 61 engineered features)
# Use dataset_engineered.csv structure
sample_data = np.array([[...]])  # 64 features

# Scale and predict
scaled_data = scaler.transform(sample_data)
prediction = model.predict(scaled_data)

# 0 = Low Risk, 1 = Medium Risk, 2 = High Risk
risk_labels = ['Low Risk', 'Medium Risk', 'High Risk']
print(f"Predicted: {risk_labels[prediction[0]]}")
```

### Training from Scratch

```powershell
# Run complete pipeline (Tasks 1.1-1.5)
python src/corrected_training.py          # Traditional ML
python src/deep_learning_models.py        # Neural networks
python src/advanced_ensemble.py           # Best models
python src/hyperparameter_optimization.py # Optimization
```

## ğŸ“Š Model Performance

| Model | Test Accuracy | CV Score | Status |
|-------|---------------|----------|--------|
| **Extra Trees** | **52.76%** | 50.83% | â­ Best |
| Logistic Regression | 52.26% | 52.56% | âœ… Good |
| Stacking Ensemble | 52.26% | - | âœ… Good |
| LightGBM | 51.26% | 53.20% | âœ… OK |
| Random Forest | 51.26% | 51.91% | âœ… OK |
| MLP (Deep Learning) | 50.25% | 50.00% | âš ï¸ Underperformed |

### Per-Class Performance (Extra Trees)

| Class | Precision | Recall | F1-Score | Samples |
|-------|-----------|--------|----------|---------|
| Low Risk | 77% | 39% | 52% | 69 |
| Medium Risk | 43% | 82% | 56% | 68 |
| High Risk | 67% | 35% | 46% | 62 |

**Key Issue**: Model biased toward Medium Risk predictions. Low and High risk classes need improvement.

## ğŸ”¬ Technical Approach

### Phase 1 Pipeline
1. **Data Augmentation** (SMOTE + Gaussian Noise)
   - 150 real samples â†’ 663 samples
   - Balanced class distribution
   - +10% accuracy improvement

2. **Feature Engineering** (64 features)
   - Polynomial features (TempÂ², TempÂ³)
   - Interaction features (TempÃ—ECG, TempÃ—Pressure)
   - Statistical features (Z-scores, percentiles)
   - Domain features (Critical_Vitals, Multiple_Abnormalities)
   - **Result**: 0% improvement (curse of dimensionality)

3. **Model Development**
   - Traditional ML: Logistic Regression, SVM, Decision Tree
   - Ensemble: Random Forest, Extra Trees, Gradient Boosting
   - Deep Learning: MLP, 1D-CNN
   - Advanced: CatBoost, LightGBM, XGBoost
   - Meta-Learning: Stacking, Voting

4. **Optimization**
   - Bayesian optimization with Optuna (50 trials/model)
   - Cross-validation (10-fold stratified)
   - Early stopping and regularization

## ğŸ“ˆ Key Findings

### What Worked âœ…
- **Data augmentation** (+10% impact) - Most effective intervention
- **Tree-based ensembles** (Extra Trees, Random Forest) - Consistent 51-53%
- **Proper evaluation** (199 test samples vs original 11)

### What Didn't Work âŒ
- **Feature engineering** (0% impact) - Too many features for dataset size
- **Deep learning** (-2% impact) - Requires 1000s of samples
- **Hyperparameter optimization** (-1% impact) - Hit performance ceiling

### Root Cause
Fundamental limitation: **Only 150 real samples**. Synthetic augmentation helps but has limits.

## ğŸ’¡ Recommendations

### Critical Priority
1. **Collect 500-1000 real samples** (Expected: +15-20% improvement)
2. **Consult medical domain experts** for feature validation

### If continuing with current data
3. Focus on class imbalance handling (SMOTE variants, class weights)
4. Simplify to 5-15 most important features
5. Optimize decision thresholds per class

### Realistic Expectations
- **Current ceiling**: 52-58% (with perfect tuning)
- **With 500 samples**: 70-80% achievable
- **To reach 85%**: Need 1000-2000 samples + domain features

## ğŸ“„ Documentation

- **[PHASE1_FINAL_REPORT.md](reports/PHASE1_FINAL_REPORT.md)** - Complete Phase 1 analysis
- **[PROGRESS_SUMMARY_FINAL.md](PROGRESS_SUMMARY_FINAL.md)** - Quick overview
- **[MODEL_IMPROVEMENT_PLAN.md](MODEL_IMPROVEMENT_PLAN.md)** - Original roadmap
- **[EXECUTIVE_SUMMARY.md](reports/EXECUTIVE_SUMMARY.md)** - High-level summary

## ğŸ¤ Contributing

This project is in research phase. Key areas for contribution:
- Data collection (highest priority)
- Domain-specific feature engineering
- Alternative problem formulations (e.g., binary classification)

## ğŸ“§ Contact

For questions about Phase 1 results or future collaboration, please open an issue.

---

**Project Status**: Phase 1 Complete âœ… | Phase 2 blocked on data collection

## Project structure

```
.
â”œâ”€ IotFile.ipynb
â”œâ”€ dataset.csv
â””â”€ iot_dataset.csv
```

## Tips and troubleshooting (Windows)

- Virtual environment wonâ€™t activate: Allow PowerShell scripts for the current user.
  ```powershell
  Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
  ```
- `jupyter` not found: Install it with `pip install jupyter` in the active virtual environment.
- Plot rendering issues: Re-run the cell that sets plotting backend (if any), or restart the kernel and `Run All`.

## Next steps / roadmap

- Add a training script (`train.py`) and export the best model with `joblib`
- Add unit tests and a simple CLI for inference
- Hyperparameter tuning (GridSearchCV/RandomizedSearchCV)
- Feature engineering and scaling for algorithms that are sensitive to feature scales

## License

No license has been specified for this repository. If you plan to share or reuse, consider adding a license (e.g., MIT).

## Acknowledgements

- IoT health monitoring concept and classic ML baselines (LogReg, NB, DT, SVM)
- Built with Python, pandas, scikit-learn, seaborn, matplotlib, and Jupyter Notebook
